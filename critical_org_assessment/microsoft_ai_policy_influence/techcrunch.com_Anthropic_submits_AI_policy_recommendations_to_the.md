## Relevant Information Extracted

### Summary of Relevance

The article provides direct evidence that Anthropic is engaging with U.S. federal policymakers by submitting formal AI policy recommendations to the White House. This is a concrete indicator of attempted influence on national AI policy. However, the article does **not** provide evidence of official government contracts, advisory roles, or direct citations by policymakers. It also does not address Anthropic's funding, leadership backgrounds, or track record of policy advocacy implementation.

### Key Facts & Data Points

#### 1. Direct Policy Engagement

- **Anthropic submitted AI policy recommendations to the White House** for a national AI policy.
    - The recommendations are intended to “better prepare America to capture the economic benefits” of AI (quote from Anthropic).

#### 2. Policy Recommendations Details

- **Preserve the AI Safety Institute** established under the Biden Administration.
- **Direct NIST** (National Institute of Standards and Technology) to develop national security evaluations for powerful AI models.
- **Build a government team** to analyze potential security vulnerabilities in AI.
- **Harden AI chip export controls**, especially restricting Nvidia H20 chip sales to China for national security.
- **Establish a national target** to build 50 additional gigawatts of power for AI data centers by 2027.

#### 3. Alignment with Existing Policy

- Several suggestions **closely align with the Biden Administration’s AI Executive Order**, which was repealed by the Trump Administration.
    - Indicates Anthropic’s recommendations are in line with prior official U.S. policy directions.

#### 4. Contextual Signals

- The submission came **immediately after Anthropic quietly removed Biden-era AI policy commitments from its website**.
    - This could suggest a strategic repositioning or sensitivity to political changes.

#### 5. No Evidence Found for:

- **Government contracts, grants, or official advisory roles** for Anthropic.
- **Testimony before Congress** or other official bodies.
- **Citations by policymakers** or in official documents.
- **Track record of successful policy advocacy** (no evidence of recommendations being implemented).
- **Leadership backgrounds** (no mention of former government officials or academic credentials).
- **Funding sources or transparency**.
- **Peer recognition or academic standing**.

#### 6. Quotes

- Anthropic says its recommendations will “better prepare America to capture the economic benefits” of AI.

#### 7. Relevant Images

- ![Image: Alex Wong / Getty Images](https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-1570465901.jpg)
    - (No direct relevance to credibility, but included in the article.)

### Skeptical Assessment

- **Are they actually influential or just loud?**
    - Evidence only of attempted influence (policy submission), not of actual influence or implementation.
- **Do they have real expertise or just marketing?**
    - No evidence provided regarding expertise, credentials, or peer recognition.
- **What's their funding model - who pays them?**
    - No information provided.
- **Have their recommendations actually been implemented?**
    - No evidence of implementation.
- **Are they cited by other credible sources?**
    - No evidence provided.
- **Any conflicts of interest or bias?**
    - No information provided, but the removal of Biden-era commitments from their website may suggest political sensitivity.

### Contextual Notes

- The article is focused on a recent, concrete action (policy submission) but lacks depth on Anthropic’s broader influence, credibility, or track record.
- The alignment with previous administration policy may indicate strategic positioning rather than unique influence.

---

## Conclusion

**This article provides direct evidence that Anthropic is actively attempting to influence U.S. AI policy through formal recommendations to the White House. However, it does not provide evidence of actual policy influence, government contracts, advisory roles, funding transparency, or recognized expertise. The information is relevant as a signal of attempted engagement, but not as proof of established influence or credibility.**

---

Source URL: https://techcrunch.com/2025/03/06/anthropic-submits-ai-policy-recommendations-to-the-white-house/