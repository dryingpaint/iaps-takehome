## Summary of Relevance to Task

The content provides some **directly relevant information** about the Federation of American Scientists (FAS) regarding their funding, leadership, and activities in the AI policy space. However, it does **not** provide concrete evidence of government contracts, official advisory roles, Congressional testimony, or direct citations by policymakers. The information is most relevant to the following credibility signals and skeptical questions:

- **Funding sources and transparency**
- **Leadership backgrounds**
- **Nature of activities and engagement with policymakers**
- **Expertise (as suggested by project scope and collaborators)**

There is **no evidence** in this content about:
- Government contracts, grants, or advisory roles
- Congressional testimony
- Direct citations or track record of policy implementation

## Extracted and Organized Information

### 1. Funding Sources and Transparency

- **Grant Announcement:**  
  > "The Federation of American Scientists (FAS) has received a $1.5 million grant from the Future of Life Institute (FLI) to investigate the implications of artificial intelligence on global risk."
- **Funding Purpose:**  
  > "The 18-month project supports FAS’s efforts to bring together the world’s leading security and technology experts to better understand and inform policy on the nexus between AI and several global issues..."

**Relevance:**  
This is a concrete funding disclosure, showing FAS is funded (at least for this project) by a nonprofit (FLI), not by government or industry. This partially addresses the skeptical question about who pays them, but does not clarify their overall funding model.

### 2. Leadership Backgrounds

- **CEO:** Daniel Correa  
  > "FAS’s CEO Daniel Correa noted that 'understanding and responding to how new technology will change the world is why the Federation of American Scientists was founded.'"
- **Program Director:** Jon Wolfsthal  
  > "Jon Wolfsthal, who directs FAS’ Global Risk Program..."

**Relevance:**  
Names of key leaders are provided, but **no details** about their backgrounds, government service, or credentials are given in this content.

### 3. Activities and Engagement with Policymakers

- **Project Scope:**  
  > "The project will include a series of activities, including high-level focused workshops with world-leading experts and officials on different aspects of artificial intelligence and global risk, policy sprints and fellows, and directed research, and conclude with a global summit on global risk and AI in Washington in 2026."
- **Stated Mission:**  
  > "Our work will help policy makers better understand these complex relationships."
  > "FAS works to advance progress on a broad suite of contemporary issues where science, technology, and innovation policy can deliver dramatic progress, and seeks to ensure that scientific and technical expertise have a seat at the policymaking table."

**Relevance:**  
FAS claims to engage with policymakers and officials, but **no specific examples** of direct influence, advisory roles, or policy implementation are provided.

### 4. Expertise and Peer Recognition

- **Historical Context:**  
  > "Established in 1945 by scientists in response to the atomic bomb, FAS continues to work on behalf of a safer, more equitable, and more peaceful world."
- **Collaboration with FLI:**  
  > "We’re excited to partner with FLI on this essential work..."

**Relevance:**  
FAS’s founding by prominent scientists is cited as a credibility signal, and their partnership with FLI (which is recognized in the AI safety community) may suggest peer recognition. However, **no academic credentials or peer-reviewed outputs** are mentioned.

### 5. Quotes and Key Statements

- Daniel Correa (CEO):  
  > "Our goal is not just to understand these risks, but to ensure that as AI technology advances, humanity’s ability to understand and manage the potential of this technology advances as well."
- Jon Wolfsthal (Global Risk Program Director):  
  > "Our work will help policy makers better understand these complex relationships. No one fully understands what AI will do for us or to us, but having all perspectives in the room and working to protect against negative outcomes and maximizing positive ones is how good policy starts."
- Max Tegmark (FLI President):  
  > "We are honored to support FAS in this vital work."

### 6. Images, Tables, and Media

- **No images, tables, or media** are included in the provided content.

## Context and Limitations

- The content is primarily a **grant announcement and organizational overview**.
- It provides **some insight into funding, leadership, and intended activities**, but **lacks concrete evidence** of direct policy influence, government engagement, or academic credentials.
- The information is **tangentially useful** for assessing FAS’s credibility and potential influence, but **does not answer** most skeptical questions with concrete evidence.

---

**Source URL:** https://fas.org/publication/artificial-intelligence-global-risk