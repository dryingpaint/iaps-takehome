## Summary of Relevance

This article contains **relevant information** for assessing Anthropic's actual influence on AI policy, particularly regarding their relationship with the U.S. government, their policy commitments, and their responsiveness to political changes. The article provides concrete evidence about Anthropic's participation in government-led voluntary commitments, their adjustment of public policy stances in response to political shifts, and their pursuit of government contracts.

---

## Extracted Relevant Information

### 1. Government Contracts, Grants, or Official Advisory Roles

- **Direct Evidence:**
  - "Both OpenAI and Anthropic have or are actively pursuing government contracts."
    - **Insight:** This signals a direct relationship with the U.S. government, suggesting a degree of credibility and influence, as government contracts often require vetting and ongoing engagement.

### 2. Testimony Before Congress or Other Official Bodies

- **No direct evidence in the article** regarding Anthropic testifying before Congress or holding official advisory roles.

### 3. Citations by Policymakers or in Official Documents

- **Indirect Evidence:**
  - Anthropic was included in a group of companies (OpenAI, Google, Microsoft, Meta, Inflection) that "announced in July 2023 that it had agreed to adhere to certain voluntary AI safety commitments proposed by the Biden Administration."
    - **Insight:** Inclusion in White House-led initiatives indicates recognition by policymakers, though no specific citations in official documents are mentioned.

### 4. Track Record of Successful Policy Advocacy

- **Partial Evidence:**
  - Anthropic adopted several practices outlined in the Biden-era voluntary commitments, such as:
    - Internal and external security tests of AI systems before release
    - Investing in cybersecurity to protect sensitive AI data
    - Developing methods of watermarking AI-generated content
  - However, the article notes these were voluntary and not legally binding, and it is unclear if Anthropic's advocacy led to policy adoption beyond their own practices.

### 5. Leadership Backgrounds (Former Government Officials, etc.)

- **No information provided** about Anthropic's leadership backgrounds or prior government service.

### 6. Funding Sources and Transparency

- **No information provided** about Anthropic's funding sources or transparency practices.

### 7. Academic Credentials and Peer Recognition

- **No information provided** about academic credentials or peer recognition.

---

## Skeptical Questions Addressed

### Are they actually influential or just loud?

- **Evidence of Influence:**
  - Participation in White House-led voluntary commitments and pursuit of government contracts suggest real influence, not just public relations.
  - Inclusion among a small group of top AI companies recognized by the administration.

### Do they have real expertise or just marketing?

- **Partial Evidence:**
  - Adoption of technical practices (security tests, watermarking, cybersecurity) indicates operational expertise, but the article does not detail the depth or impact of this expertise.

### What's their funding model - who pays them?

- **No information provided** on funding model or sources.

### Have their recommendations actually been implemented?

- **Partial Evidence:**
  - Anthropic "had already adopted a number of the practices outlined in the commitments," but the article does not specify if their recommendations were adopted by others or codified into policy.

### Are they cited by other credible sources?

- **Indirect Evidence:**
  - Their inclusion in White House initiatives and reporting by watchdog groups (The Midas Project) suggests they are monitored and referenced by policy actors and civil society, but no direct citations are mentioned.

### Any conflicts of interest or bias?

- **No explicit evidence** of conflicts of interest or bias in the article.

---

## Key Facts, Data Points, and Quotes

- **"Anthropic has quietly removed from its website several voluntary commitments the company made in conjunction with the Biden Administration in 2023 to promote safe and 'trustworthy' AI."**
- **"The commitments, which included pledges to share information on managing AI risks across industry and government and research on AI bias and discrimination, were deleted from Anthropic’s transparency hub last week, according to AI watchdog group The Midas Project."**
- **"Anthropic, along with companies including OpenAI, Google, Microsoft, Meta, and Inflection, announced in July 2023 that it had agreed to adhere to certain voluntary AI safety commitments proposed by the Biden Administration."**
- **"Both OpenAI and Anthropic have or are actively pursuing government contracts."**
- **"To be clear, Anthropic had already adopted a number of the practices outlined in the commitments, and the accord wasn’t legally binding."**
- **"Nothing in the Biden-era commitments suggested that the promise was time-bound or contingent on the party affiliation of the sitting president."**
- **"In November, following the election, multiple AI companies confirmed that their commitments hadn’t changed."**
- **"Anthropic appears to have given no notice of the change. The company didn’t immediately respond to a request for comment."**

---

## Context and Interpretation

- **Political Sensitivity:** The removal of Biden-era commitments after a change in administration (Trump repealing the AI Executive Order) suggests Anthropic is responsive to the political environment, which may affect their policy stances and influence.
- **Watchdog Oversight:** The Midas Project's monitoring of Anthropic's policy changes indicates external scrutiny and the importance of transparency for perceived influence.
- **Industry Cohort:** Anthropic is grouped with major AI firms in policy discussions, indicating a seat at the table but not necessarily unique influence.

---

## Relevant Images

- ![Anthropic Claude logo](https://techcrunch.com/wp-content/uploads/2023/11/Claude2_Blog_V1-1.webp)
  - **Image Credits:** Anthropic

---

## Tangentially Related Content

- The article discusses similar policy shifts by OpenAI and broader industry trends in response to the Trump Administration's approach to AI governance. This context helps situate Anthropic's actions within a larger pattern but is not directly about Anthropic's own influence.

---

## Conclusion

**The article provides concrete evidence that Anthropic:**
- Was recognized by the U.S. government as a key AI company and included in voluntary policy commitments
- Has adopted at least some policy practices aligned with government priorities
- Is pursuing or holds government contracts, indicating a direct line of influence
- Is responsive to political changes, as evidenced by the quiet removal of policy commitments
- Is monitored by watchdog groups, suggesting their actions are seen as influential or significant in the policy space

**However, the article does not provide information on:**
- Leadership backgrounds
- Funding sources or transparency
- Academic credentials or peer recognition
- Specific policy outcomes directly attributable to Anthropic

---

Source URL: https://techcrunch.com/2025/03/05/anthropic-quietly-removes-biden-era-ai-policy-commitments-from-its-website/