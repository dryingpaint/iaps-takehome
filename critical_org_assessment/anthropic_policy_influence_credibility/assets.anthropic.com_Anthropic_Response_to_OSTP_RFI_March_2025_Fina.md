# Anthropic's Influence on AI Policy: Evidence from OSTP RFI Submission (March 2025)

## Brief Summary

This document is Anthropic’s formal response to a Request for Information (RFI) from the White House Office of Science and Technology Policy (OSTP) regarding the development of a national AI Action Plan. The content provides **concrete evidence** of Anthropic’s engagement with U.S. government agencies, its participation in official policy processes, and its recommendations for national AI policy. The submission includes references to collaborations with government institutes, policy advocacy, and internal initiatives relevant to AI policy and governance.

---

## 1. Government Contracts, Grants, or Official Advisory Roles

- **Direct Evidence of Government Engagement:**
    - Anthropic reports that its customers include “U.S. government agencies” (p. 1).
    - Anthropic participated in “voluntary security exercises conducted in partnership with the U.S. and U.K. AI Safety and Security Institutes” (p. 3).
    - The document references “MOUs [Memoranda of Understanding] signed with U.S. AI companies—including Anthropic—to advance the state of the art in third-party testing of AI systems for national security risks” (p. 4).
    - Recommends that the government “partner with industry leaders to substantially enhance security protocols at frontier AI laboratories” (p. 5).

- **No explicit mention of direct government contracts, grants, or official advisory roles** for Anthropic in this document, but evidence of formal collaboration and recognized status as a stakeholder.

---

## 2. Testimony Before Congress or Other Official Bodies

- **No direct evidence** in this document of Anthropic providing testimony before Congress or other legislative bodies.
- However, this formal submission to the OSTP is itself an official engagement in the federal policy process.

---

## 3. Citations by Policymakers or in Official Documents

- **Referenced by U.S. Government:**
    - Anthropic’s work is referenced in the context of the “October 2024 National Security Memorandum (NSM) on Artificial Intelligence and the accompanying Framework to Advance AI Governance and Risk Management in National Security” (p. 7).
    - Anthropic’s Claude 3.7 Sonnet system card and other internal documents are cited as evidence in policy recommendations.

- **Anthropic Cites Policymakers:**
    - Cites U.S. Department of Commerce, NIST, and other federal agencies as partners or relevant authorities.
    - References to the “Diffusion Rule” (Department of Commerce, Jan 2025) and other U.S. policy instruments.

---

## 4. Track Record of Successful Policy Advocacy

- **Policy Recommendations Incorporated into Federal Frameworks:**
    - Anthropic’s recommendations align with and reference existing federal initiatives (e.g., AI Safety Institute, export controls, NSM on AI).
    - The document advocates for specific regulatory actions (e.g., closing export control loopholes, enhancing procurement, increasing BIS funding).

- **No direct evidence** that Anthropic’s recommendations have been implemented, but the company is clearly recognized as a policy stakeholder and is actively shaping the policy conversation.

---

## 5. Leadership Backgrounds (Former Government Officials, etc.)

- **Limited Information Provided:**
    - The only leadership mentioned is CEO Dario Amodei, referenced for his essay on AI (“Machines of Loving Grace”).
    - No explicit mention of former government officials or advisory board members with government backgrounds in this document.

---

## 6. Funding Sources and Transparency

- **Funding and Valuation:**
    - Anthropic describes itself as “one of the ten most valuable private companies in the U.S.” (p. 1).
    - No explicit disclosure of funding sources or investors in this document.
    - No mention of funding transparency or potential conflicts of interest.

---

## 7. Academic Credentials and Peer Recognition

- **Peer Collaboration and Recognition:**
    - Anthropic references collaboration with leading AI safety researchers and institutes (e.g., U.S. and U.K. AI Safety and Security Institutes).
    - Cites external research, such as Y. Bengio et al., “International AI Safety Report” (Jan 2025), indicating engagement with the academic community.
    - No explicit mention of peer-reviewed publications or academic awards.

---

## 8. Concrete Evidence of Influence and Expertise

### a. Evidence of Influence

- **Direct engagement with OSTP and policy process** (this submission).
- **MOUs with U.S. government** for AI safety testing.
- **Participation in security exercises with U.S. and U.K. AI Safety Institutes**.
- **Cited as a source of technical insight** in government policy frameworks (NSM on AI, Diffusion Rule).

### b. Evidence of Expertise

- **Technical Leadership:** Anthropic claims to have released “the most powerful and capable commercially-available AI system in the world” (Claude 3.7 Sonnet).
- **Internal Testing and Evaluation:** Describes advanced internal protocols for testing biological weapons risks and participation in third-party evaluations.
- **Development of Economic Impact Index:** Launched the “Anthropic Economic Index” to track AI’s impact on labor markets, using BLS O*NET framework (p. 8).

### c. Evidence of Policy Advocacy

- **Detailed, actionable policy recommendations** provided to the White House, including:
    - Strengthening export controls on chips and model weights.
    - Enhancing security at AI labs.
    - Expanding energy infrastructure for AI.
    - Accelerating federal AI procurement.
    - Improving economic monitoring of AI’s impact.

---

## 9. Skeptical Questions Addressed

| Skeptical Question | Evidence/Commentary |
|--------------------|--------------------|
| Are they actually influential or just loud? | Evidence of formal engagement with OSTP, MOUs with government, and participation in security exercises suggests real influence. |
| Do they have real expertise or just marketing? | Technical details about model testing, security exercises, and economic impact tracking indicate substantive expertise. |
| What's their funding model - who pays them? | Not disclosed in this document. Only mentions status as a top private company. |
| Have their recommendations actually been implemented? | No direct evidence of implementation, but recommendations align with and reference existing federal actions. |
| Are they cited by other credible sources? | Cited in the context of federal frameworks and by the AI Safety Institutes. |
| Any conflicts of interest or bias? | No explicit disclosure or discussion of conflicts of interest in this document. |

---

## 10. Key Quotes

- “Our customers, ranging from Fortune 500 companies and U.S. government agencies to small businesses and consumers, use Claude as an AI co-pilot...” (p. 1)
- “Our most recent system, Claude 3.7 Sonnet, demonstrates concerning improvements in its capacity to support aspects of biological weapons development—insights we uncovered through our internal testing protocols and validated through voluntary security exercises conducted in partnership with the U.S. and U.K. AI Safety and Security Institutes.” (p. 3)
- “Preserve the AI Safety Institute in the Department of Commerce and build on the MOUs it has signed with U.S. AI companies—including Anthropic—to advance the state of the art in third-party testing of AI systems for national security risks.” (p. 4)
- “In February, we launched the Anthropic Economic Index in February, an initiative designed to assess AI's impact on labor markets by correlating our usage data with the Bureau of Labor Statistics (BLS) O*NET framework.” (p. 8)

---

## 11. Relevant Tables, Images, or Media

- **No images or tables** are included in the document.

---

## 12. Context and Limitations

- This is a **policy advocacy document** submitted as part of a federal RFI process; it is designed to influence policy and demonstrate Anthropic’s expertise and engagement.
- The document provides **concrete evidence of government engagement and technical expertise**, but lacks transparency on funding and leadership backgrounds.
- No direct evidence of Congressional testimony, nor explicit confirmation that policy recommendations have been adopted.

---

## 13. Tangentially Related Content

- Some recommendations (e.g., energy infrastructure, economic monitoring) are broader than AI policy per se but are relevant to the national policy context.

---

## Conclusion

This document provides **substantial evidence** of Anthropic’s active engagement with U.S. government agencies, its technical expertise, and its recognized role as a policy stakeholder. While some key credibility signals (e.g., funding transparency, leadership backgrounds) are missing, the submission demonstrates Anthropic’s **real influence** in federal AI policy discussions and its capacity to shape policy recommendations at the highest level.

---

Source URL: https://assets.anthropic.com/m/4e20a4ab6512e217/original/Anthropic-Response-to-OSTP-RFI-March-2025-Final-Submission-v3.pdf