## Relevant Content Extracted from the Document

### Brief Summary

This document is a policy recommendation white paper authored by Anthropic, advocating for increased investment in the National Institute of Standards and Technology (NIST) to strengthen U.S. AI innovation and safety. It is intended for Congressional and policymaker audiences, specifically the Subcommittee on Commerce, Justice, Science, and Related Agencies of both the U.S. House and Senate Appropriations Committees. The document provides concrete recommendations, budget analysis, and rationale for expanding NIST’s AI-related capabilities.

The content is directly relevant to the task, as it provides evidence of Anthropic’s attempts to influence AI policy, their approach to policy advocacy, and some signals of credibility and expertise. However, it does not provide evidence of government contracts, grants, or official advisory roles, nor does it provide direct evidence of Congressional testimony or implementation of their recommendations.

---

## Organized Extraction of Relevant Information

### 1. **Policy Advocacy and Influence**

#### a. **Direct Policy Recommendations**
- Anthropic recommends that Congress invest in NIST by:
  - Adding 22 additional staff positions for AI programs (doubling current staff)
  - Increasing NIST’s AI program budget by $15 million over FY 2023 levels
- The recommendations are targeted at the Subcommittee on Commerce, Justice, Science, and Related Agencies of both the U.S. House and Senate Appropriations Committees.

#### b. **Engagement with Policymakers**
- Anthropic explicitly states willingness to engage with policymakers:
  > "Anthropic would be delighted to talk further about the importance of a robust measurement capacity with policymakers both in the United States and abroad."
- The document is structured as a policy brief, indicating intent to influence legislative funding decisions.

#### c. **Concrete Evidence of Policy Engagement**
- The document references review and analysis of NIST budget submissions and Congressional appropriations, demonstrating familiarity with the policy process.
- Anthropic’s recommendations are contextualized within historical Congressional funding and staffing decisions for NIST.

#### d. **Track Record of Advocacy**
- No direct evidence is provided that Anthropic’s recommendations have been implemented or cited by policymakers.
- No mention of previous successful policy advocacy outcomes.

---

### 2. **Credibility Signals**

#### a. **Expertise and Technical Knowledge**
- The document demonstrates technical understanding of AI evaluation, measurement, and risk management.
- Anthropic references specific NIST programs (AI Risk Management Framework, Face Recognition Vendor Test) and suggests detailed improvements and expansions.
- The recommendations include technical proposals such as:
  - Cataloging and validating AI benchmarks
  - Designing new evaluations
  - Developing technical and disclosure standards
  - Creating testbeds for large language models (LLMs)

#### b. **Academic and Industry Citations**
- The document cites reputable sources, including:
  - NIST publications and budget documents
  - OpenAI (GPT-4)
  - DeepMind (AlphaFold)
  - Google Research (Imagen)
  - Stanford University’s AI Index Report
  - Peer-reviewed research (Ganguli et al., ACM Digital Library)
- This demonstrates engagement with current academic and industry research.

#### c. **Organizational Structure**
- Anthropic describes itself as:
  > "a public benefit corporation and AI safety research company that is working to build reliable, interpretable, and steerable AI systems."
- No mention of government contracts, grants, or official advisory roles.
- No evidence of leadership with government backgrounds in this document.

#### d. **Funding Sources and Transparency**
- No information is provided about Anthropic’s funding sources or financial transparency.

#### e. **Peer Recognition**
- The document does not mention awards, peer-reviewed publications by Anthropic, or external recognition.

---

### 3. **Skeptical Questions Addressed**

#### a. **Are They Actually Influential or Just Loud?**
- The document shows Anthropic is actively attempting to influence policy by producing targeted recommendations for Congressional committees.
- No evidence is provided that their recommendations have been adopted or cited by policymakers.

#### b. **Do They Have Real Expertise or Just Marketing?**
- The technical detail and references suggest real expertise in AI safety and evaluation.
- The document is not overtly self-promotional; it is focused on policy analysis and recommendations.

#### c. **What’s Their Funding Model – Who Pays Them?**
- No information provided.

#### d. **Have Their Recommendations Actually Been Implemented?**
- No evidence provided.

#### e. **Are They Cited by Other Credible Sources?**
- The document itself cites credible sources, but does not provide evidence of being cited by others.

#### f. **Any Conflicts of Interest or Bias?**
- The document advocates for increased government investment in AI safety infrastructure, which could indirectly benefit Anthropic as an AI safety company.
- No explicit disclosure of potential conflicts of interest.

---

### 4. **Key Facts, Data Points, and Quotes**

#### a. **Key Quotes**
- "We argue that a strongly resourced AI program at NIST — on the order of 22 additional positions and an increase of $15 million over FY 2023 levels — can advance research and development (R&D) through the creation of a robust ecosystem of AI assurance."
- "We encourage the Subcommittee on Commerce, Justice, Science, and Related Agencies, of both the U.S. House and Senate Appropriations Committees, to consider this an investment in the development of safe and innovative AI systems that can benefit all Americans."
- "Anthropic would be delighted to talk further about the importance of a robust measurement capacity with policymakers both in the United States and abroad."

#### b. **Data Points and Figures**
- **Figure 1:** Number of staff positions working on AI-related programs at NIST from 2020-2024, showing base, requested, and actual increases, as well as Anthropic’s recommended increase.
- **Figure 2:** Amount of funding (in millions) for AI-related programs at NIST from 2020-2024, showing base, requested, and actual increases, as well as Anthropic’s recommended increase.
- **Chart:** Number of AI incidents and controversies, 2012–2021 (from AIAAIC Repository, AI Index Report).

#### c. **Contact Information**
- "CONTACT: POLICY@ANTHROPIC.COM"

---

### 5. **Relevant Images and Tables**

#### a. **Figures Referenced**
- **Figure 1:** Bar chart of NIST AI program staffing levels (2020-2024), including Anthropic’s recommended increase.
- **Figure 2:** Bar chart of NIST AI program funding (2020-2024), including Anthropic’s recommended increase.
- **Chart:** Number of AI incidents and controversies (2012–2021).

*(Note: Actual images are not included in this text extraction, but their content is described above.)*

---

### 6. **Contextual Notes**

- The document is a policy brief, not a research paper or a record of government engagement.
- It is evidence of Anthropic’s policy advocacy efforts and technical expertise, but not of direct government influence, contracts, or implementation.
- The document is relevant for assessing Anthropic’s approach to influencing AI policy and their credibility as a policy advocate.

---

## Conclusion

**This document provides concrete evidence of Anthropic’s policy advocacy efforts, technical expertise, and engagement with the U.S. policymaking process regarding AI safety and standards. However, it does not provide evidence of direct government contracts, advisory roles, Congressional testimony, or implementation of their recommendations. There is also no information on funding sources, leadership backgrounds, or external citations of Anthropic’s work.**

---

Source URL: https://www-cdn.anthropic.com/c429f993f5a3a5ea1808414df6e67fcb8d36ca86/Anthropic_NIST_v3.pdf